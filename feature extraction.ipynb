{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imsave\n",
    "import matplotlib.image as mpimg\n",
    "from cv2 import bitwise_and\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Upload data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "X_df = df['ImageId']\n",
    "y_df = df['Malignant']\n",
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create matrix of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(X,folder):\n",
    "    # load images\n",
    "    M = []\n",
    "    for i in range(0, X.shape[0]):\n",
    "        image = X[i]\n",
    "        mask = cv2.imread(folder + '/im_segmentations/'  + str(image) + '_segmentation.jpg') \n",
    "        #upload segmentaion and resize (image*image_seg) after applying the mask\n",
    "        #link = 'data/scaled' + '/'  + str(image) + '_segmentation.jpg'\n",
    "        img_down = resize(mask,(250,250), mode='reflect',anti_aliasing = True) \n",
    "        #plt.imsave(image+'.jpg',img_down,cmap='gray')\n",
    "        M.append(img_down)\n",
    "    return np.asarray(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training matrix\n",
    "M = build_matrix(X,folder='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/training_segm.npy',M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input matrix\n",
    "images = np.load('data/data_training_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input matrix\n",
    "images_segm = np.load('data/data_training_matrix_segmentaions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_segm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 250, 250)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:259: error: (-2:Unspecified error) in function '__cdecl cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 250\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-44959a792d4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.0) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:259: error: (-2:Unspecified error) in function '__cdecl cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 250\n"
     ]
    }
   ],
   "source": [
    "im = images[0].T\n",
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "image, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(countours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(image, mask, contour):\n",
    "    \"\"\"\n",
    "    This method extracts Asymmetry, Border, and Diamter features along with\n",
    "    lesion area, centroid, and perimeter. Performs affine transformation\n",
    "    :param image: 3-d numpy array of an RGB image\n",
    "    :param mask: binary image of the lesion mask image\n",
    "    :param contour: list of contour points of the lesion\n",
    "    :return: a list of all the features along with area, centroid,\n",
    "    perimeter of the lesion, and transformed image\n",
    "    \"\"\"\n",
    "    moments = cv2.moments(contour)\n",
    "    #            contour_area = moments['m00']\n",
    "    # (mH, mW) = mask.shape[:2]\n",
    "    contour_area = cv2.countNonZero(mask)\n",
    "    try:\n",
    "        contour_centroid = [int(moments['m10'] / moments['m00']),\n",
    "                            int(moments['m01'] / moments['m00'])]\n",
    "        contour_perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "        # Get max and min diameter\n",
    "        rect = cv2.fitEllipse(contour)\n",
    "        (x, y) = rect[0]\n",
    "        (w, h) = rect[1]\n",
    "        angle = rect[2]\n",
    "\n",
    "        if w < h:\n",
    "            if angle < 90:\n",
    "                angle -= 90\n",
    "            else:\n",
    "                angle += 90\n",
    "        rows, cols = mask.shape\n",
    "        rot = cv2.getRotationMatrix2D((x, y), angle, 1)\n",
    "        cos = np.abs(rot[0, 0])\n",
    "        sin = np.abs(rot[0, 1])\n",
    "        nW = int((rows * sin) + (cols * cos))\n",
    "        nH = int((rows * cos) + (cols * sin))\n",
    "\n",
    "        rot[0, 2] += (nW / 2) - cols / 2\n",
    "        rot[1, 2] += (nH / 2) - rows / 2\n",
    "\n",
    "        warp_mask = cv2.warpAffine(mask, rot, (nH, nW))\n",
    "        warp_img = cv2.warpAffine(image, rot, (nH, nW))\n",
    "        warp_img_segmented = cv2.bitwise_and(warp_img, warp_img,\n",
    "                                             mask=warp_mask)\n",
    "\n",
    "        im_mask, cnts, hierarchy = cv2.findContours(warp_mask, cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_NONE)\n",
    "        areas = [cv2.contourArea(c) for c in cnts]\n",
    "        contour = cnts[np.argmax(areas)]\n",
    "        xx, yy, nW, nH = cv2.boundingRect(contour)\n",
    "        #        cv2.rectangle(warp_mask,(xx,yy),(xx+w,yy+h),(255,255,255),2)\n",
    "        warp_mask = warp_mask[yy:yy + nH, xx:xx + nW]\n",
    "\n",
    "        # get horizontal asymmetry\n",
    "        flipContourHorizontal = cv2.flip(warp_mask, 1)\n",
    "        flipContourVertical = cv2.flip(warp_mask, 0)\n",
    "\n",
    "        diff_horizontal = cv2.compare(warp_mask, flipContourHorizontal,\n",
    "                                      cv2.CV_8UC1)\n",
    "        diff_vertical = cv2.compare(warp_mask, flipContourVertical,\n",
    "                                    cv2.CV_8UC1)\n",
    "\n",
    "        diff_horizontal = cv2.bitwise_not(diff_horizontal)\n",
    "        diff_vertical = cv2.bitwise_not(diff_vertical)\n",
    "\n",
    "        h_asym = cv2.countNonZero(diff_horizontal)\n",
    "        v_asym = cv2.countNonZero(diff_vertical)\n",
    "\n",
    "        return [{'area': int(contour_area), 'centroid': contour_centroid,\n",
    "                 'perimeter': int(contour_perimeter),\n",
    "                 'B': round(\n",
    "                     (contour_perimeter ** 2) / (4 * np.pi * contour_area), 2),\n",
    "                 'D1': max([nW, nH]), 'D2': min([nW, nH]),  # Normalize params\n",
    "                 'A1': round(float(h_asym) / contour_area, 2),\n",
    "                 'A2': round(float(v_asym) / contour_area, 2)},\n",
    "                cv2.bitwise_not(diff_horizontal),\n",
    "                cv2.bitwise_not(diff_vertical),\n",
    "                warp_img_segmented]\n",
    "    except:\n",
    "return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
